package practical

/*
算法实战（三）：剖析高性能队列Disruptor背后的数据结构和算法

Disruptor 简介
	一种内存消息队列
	从功能上讲，它其实有点儿类似 Kafka
	和 Kafka 不同的是，Disruptor 是线程之间用于消息传递的队列
	在 Apache Storm、Camel、Log4j 2 等很多知名项目中都有广泛应用
	获得过 Oracle 官方的 Duke 大奖
vs
	Disruptor 性能表现非常优秀，算得上是最快的内存消息队列了
	比 Java 中另外一个非常常用的内存消息队列 ArrayBlockingQueue（ABS）的性能，要高一个数量级
Disruptor 是如何做到如此高性能的？其底层依赖了哪些数据结构和算法？

基于循环队列的“生产者 - 消费者模型”
	生产者 - 消费者模型”
		“生产者”生产数据，并且将数据放到一个中心存储容器中
		之后，“消费者”从中心存储容器中，取出数据消费
	中心存储容器，是用什么样的数据结构来实现的呢？
		队列：06.queue.go
			链表，链式队列：
				队列的大小事先不确定，理论上可以支持无限大
				链表支持快速地动态扩容
			数组，顺序队列：
				实现一个有界队列，队列的大小事先确定
				当队列中数据满了之后，生产者就需要等待
				直到消费者消费了数据，队列有空闲位置的时候，生产者才能将数据放入
		有界队列的应用场景更加广泛
			机器内存是有限的。而无界队列占用的内存数量是不可控的
			对于实际的软件开发，不可控的因素，就会有潜在的风险
			在某些极端情况下，无界队列就有可能因为内存持续增长，而导致 OOM（Out of Memory）错误
		循环队列
			非循环的顺序队列在添加、删除数据的工程中，会涉及数据的搬移操作，导致性能变差
			循环队列正好可以解决这个数据搬移的问题，所以，性能更加好
	借助循环队列，实现一个最简单的“生产者 - 消费者模型”
		// TODO
		为了简单，没有用到线程相关的操作
		采用了“当队列满了之后，生产者就轮训等待；当队列空了之后，消费者就轮训等待”这样的措施
		问题：如果有多个生产者在并发地往队列中写入数据，或者多个消费者并发地从队列中消费数据
			多个生产者写入的数据可能会互相覆盖
			多个消费者可能会读取重复的数据
		数据互相覆盖/重复读取，为什么会发生呢？
		如何解决这种线程并发往队列中添加数据时，导致的数据覆盖、运行不正确问题呢？
		// TODO
基于加锁的并发“生产者 - 消费者模型”
	最简单的处理方法
		给相应段的代码加锁，同一时间只允许一个线程执行 add() 函数
		就相当于将这段代码的执行，由并行改成了串行
	问题
		加锁将并行改成串行，必然导致多个生产者同时生产数据的时候，执行效率的下降
		优化：
			用CAS（compare and swap，比较并交换）操作等减少加锁的粒度
			https://en.wikipedia.org/wiki/Compare-and-swap

基于无锁的并发“生产者 - 消费者模型”
	Disruptor 基本思想：尽管 Disruptor 的源码读起来很复杂，但是基本思想其实非常简单
		生产者
			往队列中添加数据之前，先申请可用空闲存储单元，并且是批量地申请连续的 n 个（n≥1）存储单元
			申请到这组连续的存储单元之后，后续往队列中添加元素，就可以不用加锁了，因为这组存储单元是这个线程独享的
			不过，申请存储单元的过程是需要加锁的
		消费者
			先去申请一批连续可读的存储单元（这个申请的过程也是需要加锁的）
			当申请到这批存储单元之后，后续的读取操作就可以不用加锁了
		弊端
			如果生产者 A 申请到了一组连续的存储单元，假设是下标为 3 到 6 的存储单元
			生产者 B 紧跟着申请到了下标是 7 到 9 的存储单元
			那在 3 到 6 没有完全写入数据之前，7 到 9 的数据是无法读取的
			补充：
			每个线程都是一个生产者
			对于其中一个生产者申请写入n个元素，则返回列队中对应的最大下标位置(比如当前申请写入3个，从下标3开始，返回的最大下标就是6)，456就是这个生产者所申请到的独享空间
			生产者同时会带有一个标记，记录当前写入成功的下标(比如当前写入到5，标记的值就为5，用来标记自身是否全部写入完成)，这是对于单独的一个生产者
			对于多个生产者来说，都是如此的，比如有两个生产者，A申请了456，B申请了789，此时A写入到了5，A的标记是5，B写入到了8，B的标记是8，队列中对应6和9的位置是没有数据的
			这样是没有问题的，此刻暂停，来看下多消费者同时读数据
			消费者A*申请到读取3个元素，消费中B*申请读到了3个元素，那么要申请的连续最大元素个数就是6，对应此刻的下标就是9，这里会触发disruptor的设计机制，从3开始，会依次检测对位置的元素是否生产成功，此刻这里A写到了5，B写到了8，6位置还没有生产成功的，那么机制就会返回可消费的最大下标，也就是5，然后消费者只会读取下标4到5两个元素进行消费
			也就是文中小争哥所说的”3 到 6 没有完全写入数据之前，7 到 9 的数据是无法读取的“->其实就是disruptor找到了还没有生产出的元素，后面的数据都是无法读取的，其实很简单。不知道这里的解释看懂了没有，有兴趣的话可以自己去看下disruptor的设计实现，而且图片会比文字更加直观
		示例
			03.disruptor.jpg
	源码
		Disruptor 采用的是 RingBuffer 和 AvailableBuffer 这两个结构，来实现上述功能
		https://github.com/LMAX-Exchange/disruptor
		Golang：https://github.com/smarty-prototypes/go-disruptor

总结
	v1.0：常见的内存队列往往采用循环队列来实现
		对于只有一个生产者和一个消费者的场景，已经足够了
		当存在多个生产者或者多个消费者的时候，单纯的循环队列的实现方式，就无法正确工作了
		多个生产者在同时往队列中写入数据的时候，在某些情况下，会存在数据覆盖的问题。而多个消费者同时消费数据，在某些情况下，会存在消费重复数据的问题
	v2.0：对写入和读取过程加锁
		最简单、暴力的解决方法
		将原来可以并行执行的操作，强制串行执行，相应地就会导致操作性能的下降
	v3.0：高性能并发队列
		Disruptor 采用了“两阶段写入”的方法
		在写入数据之前，先加锁申请批量的空闲存储单元，之后往队列中写入数据的操作就不需要加锁了，写入的性能因此就提高了
		在读取数据之前，先加锁申请批量的可读取的存储单元，之后从队列中读取数据的操作也就不需要加锁了，读取的性能因此也就提高了

思考
	为了提高存储性能，我们往往通过分库分表的方式设计数据库表
	假设我们有 8 张表用来存储用户信息。这个时候，每张用户表中的 ID 字段就不能通过自增的方式来产生了。因为这样的话，就会导致不同表之间的用户 ID 值重复
	为了解决这个问题，我们需要实现一个 ID 生成器，可以为所有的用户表生成唯一的 ID 号
	那现在问题是，如何设计一个高性能、支持并发的、能够生成全局唯一 ID 的 ID 生成器呢？
		参考：
			1）分库分表也可以使用自增主键，可以设置增加的步长。8台机器分别从1、2、3...开始，步长8。从1开始的下一个id是9，与其他的不重复就可以了
			2）redis或者zk应该也能生成自增主键，不过它们的写性能可能不能支持真正的高并发
			3）开放独立的id生成服务。最有名的算法应该是snowflake，snowflake的好处是基本有序，每秒钟可以生成很大的量，容易水平扩展
				也可以用上 disruptor，用自己生成id算法，提前生成id存入 disruptor，预估一下峰值时业务需要的id量，比如提前生成50万
		如何实现高性能的 ID 生成器？
			E:\gothmslee\algo\beauty\practical\05.short_ip.go
	// TODO
*/
