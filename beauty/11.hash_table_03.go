package beauty

/*
LRU 缓存淘汰算法
	一个缓存（cache）系统主要包含下面这几个操作：
		往缓存中添加一个数据
		从缓存中删除一个数据
		在缓存中查找一个数据
	双向链表+散列表
		散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中
		一个链是双向链表，另一个链是散列表中的拉链
		前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中
		查找：O(1)
		删除：O(1)
		插入：O(1)
Redis 有序集合
	细化一下 Redis 有序集合的操作
		添加一个成员对象（包含 ID、姓名和积分的用户信息）
		按照键值来删除一个成员对象
		按照键值来查找一个成员对象
		按照分值区间查找数据，比如查找积分在[100, 356]之间的成员对象
		按照分值从小到大排序成员变量
	仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢
		按照键值构建一个散列表，样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)
	Redis 有序集合的操作还有另外一类，也就是查找成员对象的排名（Rank）或者根据排名区间查找成员对象
		// TODO
Java LinkedHashMap vs LRU
	通过散列表和链表组合在一起实现的，不仅支持按照插入顺序遍历数据，还支持按照访问顺序来遍历数据
		// 10是初始大小，0.75是装载因子，true是表示按照访问时间排序
		HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true);
		m.put(3, 11);
		m.put(1, 12);
		m.put(5, 23);
		m.put(2, 22);

		m.put(3, 26);
		m.get(5);

		for (Map.Entry e : m.entrySet()) {
		  System.out.println(e.getKey());
		}
		输出：1,2,3,5
	按照访问时间排序的 LinkedHashMap 本身就是一个支持 LRU 缓存淘汰策略的缓存系统
	LinkedHashMap 中的“Linked”实际上是指的是双向链表，并非指用链表法解决散列冲突

为什么散列表和链表经常会一起使用？
	散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的
	也就说，它无法支持按照某种顺序快速地遍历数据，如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历

	散列表是动态数据结构，不停地有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低
	为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。

思考
	上述例子中，如果把双向链表改成单链表，还能否正常工作呢？为什么呢？
		删除结点需要拿到前驱结点，O(n)
	假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历
	假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：
		根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息
		查找积分在某个区间的猎头 ID 列表
		查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表	// TODO
	以积分构建跳表，以ID构建散列表
*/
