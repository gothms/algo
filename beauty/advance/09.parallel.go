package advance

/*
并行算法：如何利用并行处理提高算法的执行效率？

工程中
	时间复杂度是衡量算法执行效率的一种标准，但是，时间复杂度并不能跟性能划等号
	在真实的软件开发中，即便在不降低时间复杂度的情况下，也可以通过一些优化手段，提升代码的执行效率
	对于实际的软件开发来说，即便是像 10%、20% 这样微小的性能提升，也是非常可观的
当算法无法再继续优化的情况下，我们该如何来进一步提高执行效率呢？
如何借助并行计算的处理思想对算法进行改造？

并行排序
	需求分析
		假设要给大小为 8GB 的数据进行排序，并且机器的内存可以一次性容纳这么多数据
		从理论上讲，这个排序问题，已经很难再从算法层面优化了
		利用并行的处理思想，我们可以很轻松地将这个给 8GB 数据排序问题的执行效率提高很多倍
		实现思路有下面两种：
			第一种是对归并排序并行化处理
			第二种是对快速排序并行化处理
	归并排序并行化处理
		将这 8GB 的数据划分成 16 个小的数据集合，每个集合包含 500MB 的数据
		用 16 个线程，并行地对这 16 个 500MB 的数据集合进行排序
		16 个小集合分别排序完成之后，再将这 16 个有序集合合并
	快速排序并行化处理
		扫描一遍数据，找到数据所处的范围区间，把这个区间从小到大划分成 16 个小区间，将 8GB 的数据划分到对应的区间中
		针对这 16 个小区间的数据，启动 16 个线程，并行地进行排序
		等到 16 个线程都执行结束之后，得到的数据就是有序数据了
	对比
		共同点
			分治思想，对数据进行分片
			并行处理
		区别
			归并：先随意地对数据分片，排序之后再合并
			快排：先对数据按照大小划分区间，然后再排序，排完序就不需要再处理了
	读写效率
		需求分析
			要排序的数据规模不是 8GB，而是 1TB
			问题的重点就不是算法的执行效率了，而是数据的读取效率
			因为 1TB 的数据肯定是存在硬盘中，无法一次性读取到内存中，这样在排序的过程中，就会有频繁地磁盘数据的读取和写入
		重点
			如何减少磁盘的 IO 操作，减少磁盘数据读取和写入的总量，就变成了优化的重点
			思考如何优化
并行查找
	需求分析：动态扩容
		如果给动态数据构建索引，在数据不断加入的时候，散列表的装载因子就会越来越大
		为了保证散列表性能不下降，我们就需要对散列表进行动态扩容
		对如此大的散列表进行动态扩容，一方面比较耗时，另一方面比较消耗内存
			比如，给一个 2GB 大小的散列表进行扩容，扩展到原来的 1.5 倍，也就是 3GB 大小
			这个时候，实际存储在散列表中的数据只有不到 2GB，所以内存的利用率只有 60%，有 1GB 的内存是空闲的
	数据“分片”
		将数据随机分割成 k 份（比如 16 份），每份中的数据只有原来的 1/k，然后针对这 k 个小数据集合分别构建散列表
		散列表的维护成本就变低了。当某个小散列表的装载因子过大的时候，可以单独对这个散列表进行扩容，而其他散列表不需要进行扩容
			假设现在有 2GB 的数据，放到 16 个散列表中，每个散列表中的数据大约是 150MB
			某个散列表需要扩容的时候，只需要额外增加 150*0.5=75MB 的内存（假设还是扩容到原来的 1.5 倍）
			无论从扩容的执行效率还是内存的利用率上，这种多个小散列表的处理方法，都要比大散列表高效
		分片算法是什么呢？
			参见 12.hash_02.go
	并行查找
		查找某个数据的时候，只需要通过 16 个线程，并行地在这 16 个散列表中查找数据
		查找性能，比起一个大散列表的做法，也并不会下降，反倒有可能提高
		插入：
			当往散列表中添加数据的时候，可以选择将这个新数据放入装载因子最小的那个散列表中，这样也有助于减少散列冲突
并行字符串匹配
	需求分析
		在文本中查找某个关键词的功能
		如果处理的是超级大的文本，那处理的时间可能就会变得很长，那有没有办法加快匹配速度呢？
	数据“分片” & 并行字符串匹配
		把大的文本，分割成 k 个小文本。假设 k 是 16
		启动 16 个线程，并行地在这 16 个小文本中查找关键词，这样整个查找的性能就提高了 16 倍
		16 倍效率的提升，从理论的角度来说并不多。但是，对于真实的软件开发来说，这显然是一个非常可观的优化
	细节
		原本包含在大文本中的关键词，被一分为二，分割到两个小文本中，这就会导致尽管大文本中包含这个关键词，但在这 16 个小文本中查找不到它
		方案：
			假设关键词的长度是 m
			在每个小文本的结尾和开始各取 m 个字符串。前一个小文本的末尾 m 个字符和后一个小文本的开头 m 个字符，组成一个长度是 2m 的字符串
			再拿关键词，在这个长度为 2m 的字符串中再重新查找一遍，就可以补上刚才的漏洞了
并行搜索
	需求分析
		对广度优先搜索算法，改造成并行算法
	并行搜索
		基于 BFS 搜索的当前层的顶点，启动多个线程，并行地搜索下一层的顶点
		在代码实现方面，原来广度优先搜索的代码实现，是通过一个队列来记录已经遍历到但还没有扩展的顶点
		现在需要利用两个队列来完成扩展顶点的工作
			假设这两个队列分别是队列 A 和队列 B
			多线程并行处理队列 A 中的顶点，并将扩展得到的顶点存储在队列 B 中
			等队列 A 中的顶点都扩展完成之后，队列 A 被清空，再并行地扩展队列 B 中的顶点，并将扩展出来的顶点存储在队列 A
			两个队列循环使用，就可以实现并行广度优先搜索算法

总结
	并行处理的实现思路
		对数据进行分片，对没有依赖关系的任务，并行地执行
	工程中 & 大数据
		并行计算是一个工程上的实现思路，尽管跟算法关系不大
		在实际的软件开发中，它确实可以非常巧妙地提高程序的运行效率，是一种非常好用的性能优化手段
		特别是，当要处理的数据规模达到一定程度之后，无法通过继续优化算法，来提高执行效率的时候
			就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率
		在很多超大规模数据处理中，并行处理的思想，应用非常广泛，比如 MapReduce 实际上就是一种并行计算框架

思考
	假设有 n 个任务，为了提高执行的效率，我们希望能并行执行任务，但是各个任务之间又有一定的依赖关系
		如何根据依赖关系找出可以并行执行的任务？
*/
