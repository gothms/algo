package advance

/*
位图：如何实现网页爬虫中的URL去重功能？

网页爬虫工作原理
	通过解析已经爬取页面中的网页链接，然后再爬取这些链接对应的网页
	需求分析
		同一个网页链接有可能被包含在多个页面中，这就会导致爬虫在爬取的过程中，重复爬取相同的网页
		如果你是一名负责爬虫的工程师，你会如何避免这些重复的爬取呢？
	方案思路
		记录已经爬取的网页链接（也就是 URL）
		在爬取一个新的网页之前，拿它的链接，在已经爬取的网页链接列表中搜索
			如果存在，那就说明这个网页已经被爬取过了
			如果不存在，那就说明这个网页还没有被爬取过，可以继续去爬取
		爬取到这个网页之后，将这个网页的链接添加到已经爬取的网页链接列表了
该如何记录已经爬取的网页链接呢？需要用什么样的数据结构呢？

算法解析
	需求分析：功能、执行效率、存储效率
		需要支持的操作有两个，添加一个 URL 和查询一个 URL
		在非功能性方面，还要求这两个操作的执行效率要尽可能高
		因为处理的是上亿的网页链接，内存消耗会非常大，所以在存储效率上，要尽可能地高效
	动态数据结构
		散列表、红黑树、跳表，都能支持快速地插入、查找数据，但是在内存消耗方面，是否可以接受呢？
	内存分析
		假设要爬取 10 亿个网页（像 Google、百度这样的通用搜索引擎，爬取的网页可能会更多），为了判重，把这 10 亿网页链接存储在散列表中
		估算下，大约需要多少内存？
			假设一个 URL 的平均长度是 64 字节，那单纯存储这 10 亿个 URL，需要大约 60GB 的内存空间
			散列表必须维持较小的装载因子，才能保证不会出现过多的散列冲突，导致操作的性能下降
			而且，用链表法解决冲突的散列表，还会存储链表指针
		所以，如果将这 10 亿个 URL 构建成散列表，那需要的内存空间会远大于 60GB，有可能会超过 100GB
			100GB 的内存要求，其实也不算太高
	分治思想
		用多台机器（比如 20 台内存是 8GB 的机器）来存储这 10 亿网页链接
		...
	分治+散列表
		已经可以解决网页爬虫的 URL 去重问题
		在添加、查询数据的效率以及内存消耗方面，是否还有进一步的优化空间呢？
散列表时间复杂度分析
	添加、查找数据，O(1)
	时间复杂度并不能完全代表代码的执行时间
		大 O 时间复杂度表示法，会忽略掉常数、系数和低阶，并且统计的对象是语句的频度
		不同的语句，执行时间也是不同的
		时间复杂度只是表示执行时间随数据规模的变化趋势，并不能度量在特定的数据规模下，代码执行时间的多少
	问题：
	1.如果时间复杂度中原来的系数是 10，通过优化将系数降为 1，那在时间复杂度没有变化的情况下，执行效率就提高了 10 倍
	2.散列表中存储的是 URL，那当查询的时候，通过哈希函数定位到某个链表之后，我们还需要依次比对每个链表中的 URL
		这个操作是比较耗时的，主要有两点原因
		a)链表中的结点在内存中不是连续存储的，所以不能一下子加载到 CPU 缓存中，没法很好地利用到 CPU 高速缓存
			所以数据访问性能方面会打折扣
		b)链表中的每个数据都是 URL，而 URL 不是简单的数字，是平均长度为 64 字节的字符串
			要让待判重的 URL，跟链表中的每个 URL，做字符串匹配
			字符串匹配操作，比起单纯的数字比对，要慢很多

位图（BitMap）
	场景描述
		有 1 千万个整数，整数的范围在 1 到 1 亿之间。如何快速查找某个整数是否在这 1 千万个整数中呢？
	散列表方案
	位图方案：特殊的散列表
		初级方案
			申请一个大小为 1 亿、数据类型为布尔类型（true 或者 false）的数组
			将这 1 千万个整数作为数组下标，将对应的数组值设置成 true
			查询：将对应的数组值 array[K]取出来，看是否等于 true
			问题：很多语言中提供的布尔类型，大小是 1 个字节的，并不能节省太多内存空间
				表示 true 和 false 两个值，只需要用一个二进制位（bit）就可以了
		二进制方案
			// TODO 代码实现
			定义 int/byte/int64 数组 bitmap
			i/32 定位 bitmap 索引
			i%32 定位 bitmap 索引位置的int 第几位
	内存空间对比
		散列表
			存储这 1 千万的数据，数据是 32 位的整型数，也就是需要 4 个字节的存储空间，那总共至少需要 40MB 的存储空间
		位图：二进制
			数字范围在 1 到 1 亿之间，只需要 1 亿个二进制位，也就是 12MB 左右的存储空间就够了
	问题
		如果数字的范围很大，是 1 到 10 亿，那位图的大小就是 10 亿个二进制位，也就是 120MB 的大小，消耗的内存空间，不降反增
		解决方案：
			布隆过滤器
			布隆过滤器本身就是基于位图的，是对位图的一种改进

布隆过滤器（Bloom Filter）
	方案思路
		使用一个 1 亿个二进制大小的位图，然后通过哈希函数，对数字进行处理，让它落在这 1 到 1 亿范围内
		比如把哈希函数设计成 f(x)=x%n，x 表示数字，n 表示位图的大小（1 亿）
		问题：hash 冲突，如 1 和 一亿零一 的hash值都是 1
		解决：
			1.传统方式：设计一个复杂点、随机点的哈希函数
			2.布隆过滤器：使用 K 个哈希函数
				对于两个不同的数字来说，经过一个哈希函数处理之后，可能会产生相同的哈希值
				经过 K 个哈希函数处理之后，K 个哈希值都相同的概率就非常低了
	K 个哈希函数
		对同一个数字进行求哈希值，那会得到 K 个不同的哈希值，我们分别记作 X1，X2，X3，…，XK
		将对应的 BitMap[X1]，BitMap[X2]，BitMap[X3]，…，BitMap[XK]都设置成 true
			用 K 个二进制位，来表示一个数字的存在
		查询
			用同样的 K 个哈希函数，对这个数字求哈希值，分别得到 Y1，Y2，Y3，…，YK
			这 K 个哈希值，对应位图中的数值是否都为 true，如果都是 true，则说明，这个数字存在
			如果有其中任意一个不为 true，那就说明这个数字不存在
	误判
		如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判
		如果某个数字经过布隆过滤器判断存在，这个时候才会有可能误判，有可能并不存在
			调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判的概率降到非常低
			尽管布隆过滤器会存在误判，但是，这并不影响它发挥大作用
网页爬虫 & 误判容忍
	很多场景对误判有一定的容忍度，比如解决网页爬虫判重的问题
		即便一个没有被爬取过的网页，被误判为已经被爬取，对于搜索引擎来说，也并不是什么大事情，是可以容忍的
		毕竟网页太多了，搜索引擎也不可能 100% 都爬取到
	方案：
		用布隆过滤器来记录已经爬取过的网页链接
		假设需要判重的网页有 10 亿，那我们可以用一个 10 倍大小的位图来存储，也就是 100 亿个二进制位
			换算成字节，那就是大约 1.2GB
执行效率比较
	hash表
		需要读取散列值相同（散列冲突）的多个网页链接，分别跟待判重的网页链接，进行字符串匹配
			这个操作涉及很多内存数据的读取，所以是内存密集型的
	布隆过滤器
		用多个哈希函数对同一个网页链接进行处理，CPU 只需要将网页链接从内存中读取一次，进行多次哈希计算，理论上讲这组操作是 CPU 密集型的
	CPU 计算比内存访问更快速

总结
	适用场景
		不需要 100% 准确的、允许存在小概率误判的大规模判重场景
	示例：统计一个大型网站的每天的 UV 数，即每天有多少用户访问了网站
		使用布隆过滤器，对重复访问的用户进行去重
	自动扩容
		当布隆过滤器中，数据个数与位图大小的比例超过某个阈值的时候，就重新申请一个新的位图
		后面来的新数据，会被放置到新的位图中
		要判断某个数据是否在布隆过滤器中已经存在，就需要查看多个位图，相应的执行效率就降低了一些
	实现
		Java 中的 BitSet类 是一个位图
		Redis 提供了 BitMap 位图类
		Google 的 Guava 工具包提供了 BloomFilter 布隆过滤器的实现

思考
	1.假设有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序？
	2.basic.12.hash_02.go 中的：数据分片 示例二、如何快速判断图片是否在图库中？
		利用分治思想，用散列表以及哈希函数，实现海量图库中的判重功能
		如果允许小概率的误判，那是否可以用布隆过滤器来解决呢？
		请参照当时的估算方法，重新估算下，用布隆过滤器需要多少台机器？
*/
