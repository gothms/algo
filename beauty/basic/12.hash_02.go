package basic

/*
哈希算法在分布式系统中有哪些应用？
	负载均衡
	数据分片
	分布式存储

负载均衡
	负载均衡算法：轮询、随机、加权轮询、hash算法...

	如何实现一个会话粘滞（session sticky）的负载均衡算法，即在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上
	方式一、维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系
		客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器
		弊端：
		如果客户端很多，映射表可能会很大，比较浪费内存空间
		客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大
	方式二、hash 算法
		对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算
		最终得到的值就是应该被路由到的服务器编号
		同一个 IP 过来的所有请求，都路由到同一个后端服务器上
数据分片
	示例一、如何统计“搜索关键词”出现的次数？
	假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？
		可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度
		流程：
			为了提高处理的速度，我们用 n 台机器并行处理
			从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模
			最终得到的值，就是应该被分配到的机器编号
			哈希值相同的搜索关键词就被分配到了同一个机器上
		设计思想：
			这个处理过程也是 MapReduce 的基本设计思想
	示例二、如何快速判断图片是否在图库中？
		假设现在我们的图库中有 1 亿张图片，如何快速判断图片是否在图库中？（hash_01 中使用了 唯一标识/信息摘要 方法）
		可以对数据进行分片，然后采用多机处理
		流程：
			准备 n 台机器，让每台机器只维护某一部分图片对应的散列表
			每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号
			然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表
			判断一个图片是否在图库中的时候，通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模
			再去对应编号的机器构建的散列表中查找
		估算需要多少台机器：
			过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节
			文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节
			用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节
			即散列表中每个数据单元就占用 152 字节
			假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75
			那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表
			所以，如果要对 1 亿张图片构建索引，需要大约十几台机器
		通用场景：
			针对这种海量数据的处理问题，都可以采用多机分布式处理
			可以突破单机内存、CPU 等资源的限制
分布式存储
	为了提高海量的用户、海量的数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存
	该如何决定将哪个数据放到哪个机器上呢？
	方案一、数据分片
		问题：
		新增机器扩容/缩容时，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上，缓存中的数据一下子就都失效了
		所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库
	方案二、一致性哈希算法
		有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间
		当有新机器加入的时候，就将某几个小区间的数据，从原来的机器中搬移到新的机器中
		既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡

		还会借助一个虚拟的环和虚拟结点，更加优美地实现出来
		扩展阅读：https://en.wikipedia.org/wiki/Consistent_hashing

思考
	哈希算法还有很多其他的应用，比如网络协议中的 CRC 校验、Git commit id 等等。除了这些，你还能想到其他用到哈希算法的地方吗？
*/
