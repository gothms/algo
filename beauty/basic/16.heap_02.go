package basic

/*
优先级队列
	在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队
应用
	赫夫曼编码
	图的最短路径
	最小生成树算法
	...
合并有序小文件
	描述：
		假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串
		希望将这些 100 个小文件合并成一个有序的大文件

	整体思路有点像归并排序中的合并函数
	使用数组：
		每次从数组中取最小字符串，都需要循环遍历整个数组，显然，这不是很高效
	使用堆：
高性能定时器
	描述：
		假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点
		定时器每过一个很小的单位时间（比如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间
		如果到达了，就拿出来执行
	每过 1 秒就臊面一边任务列表：
		任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的
		每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时
	堆：
		拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T
		时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行
		从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情
		定时器既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了
求 Top K
	静态数据集合，也就是说数据集合事先确定
		在一个包含 n 个数据的数组中，查找前 K 大数据

		可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较
		如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中
		如果比堆顶元素小，则不做处理，继续遍历数组
		O(n log K)
	动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中
		一个数据集合中有两个操作，一个是添加数据，另一个询问当前的前 K 大数据

		维护一个 K 大小的小顶堆，当有数据被添加到集合中时，拿它与堆顶的元素对比
		如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中
		如果比堆顶元素小，则不做处理
		无论任何时候需要查询当前的前 K 大数据，都可以立刻返回
求中位数
	静态数据：中位数是固定的
		一次排序，多次获取
	动态数据：中位数在不停地变动
		维护两个堆，一个大顶堆，一个小顶堆
		大顶堆就存储 n/2+1 或 n/2 个数据，小顶堆中就存储 n/2 个数据
			当两个堆中的数据个数不符合前面约定的情况
			从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定
		中位数只需要返回大顶堆的堆顶元素就可以了
如何快速求接口的 99% 响应时间？
	把这 100 个接口的响应时间按照从小到大排列，排在第 99 的那个数据就是 99% 响应时间，也叫 99 百分位响应时间
	维护两个堆，一个大顶堆，一个小顶堆
	假设当前总数据的个数是 n，大顶堆中保存 n*99% 个数据，小顶堆中保存 n*1% 个数据
	大顶堆堆顶的数据就是我们要找的 99% 响应时间
	每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是 O(logn)

假设现在有一个包含 10 亿个搜索关键词的日志文件，如何能快速获取到热门榜 Top 10 的搜索关键词呢？
	使用 MapReduce：
		假设处理的场景限定为单机，可以使用的内存为 1GB，又该如何解决呢？
	使用堆：
		首先要统计每个搜索关键词出现的频率
			可以通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数
		遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比
			出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中
	漏洞：
		如果每个搜索关键词的平均长度是 50 个字节，那存储 1 亿个关键词起码需要 5GB 的内存空间
		而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了
		而我们的机器只有 1GB 的可用内存空间，所以无法一次性将所有的搜索关键词加入到内存中。这个时候该怎么办呢？
	解决：分片
		创建 10 个空文件 00，01，02，……，09
		遍历这 10 亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同 10 取模，得到的结果就是这个搜索关键词应该被分到的文件编号
		分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB
		1GB 的内存完全可以放得下
		每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10
		然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词

思考
	有一个访问量非常大的新闻网站，希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次
	如果你是负责开发这个功能的工程师，你会如何来实现呢？
*/
