package _1_basic

/*
案例分析一：广度优先搜索
	单向广度优先搜索
		如果要计算平均复杂度，我们就取直接连接点的平均数量，假设它为 m
		所以时间复杂度就是 O(m+m*m+m*m*m+…+m^i)，取最高数量级 m^i，最后可以简化成 O(m^i)，其中 i 是从起始点开始所走的边数。这就是除了 m 之外的第二个关键因素
		考虑内存空间使用时，只需要考虑 queue 和 visited 的使用情况。两者都是在新发现一个结点时进行操作，因此新增的内存空间和被访问过的结点数成正比，同样为 O(m^i)
	双向广度优先搜索
		第一个关键点是双向搜索所要走的边数
			如果单向需要走 i 条边，那么双向是 i/2。因此时间和空间复杂度都会变为 O(2*m^(i/2)，简写为 O(m^(i/2))
			这里 i/2 中的 2 不能省去，因为它是在指数上，改变了数量级
		第二个关键点是双向搜索过程中，判断是否找到通路的方式
			单向搜索只需要判断一个点是否存在集合中，每次只有 O(1) 的复杂度。而双向搜索需要比较两个集合是否存在交集，复杂度肯定要高于 O(1)
			最常规的实现方法是，循环遍历其中一个集合 A，看看 A 中的每个元素是不是出现在集合 B 中
			假设两个集合中元素的数量都为 n，那么循环 n 次，那么时间复杂度就为 O(n)
	最后比较单向广度搜索的复杂度 O(m^i) 和双向广度搜索的复杂度 O(m^(i/2))，双向的方法更优
		不过，上面讨论的内容，都是假设每个点的直接相连点数量都很均匀，都是 m 个。如果数据不是均匀的呢？我想到了三种情况
		第一种情况，我用 a=b 来表示，也就是前面讨论的，不管从 a 和 b 哪个点出发，每个点的直接连接数量都是相当的。这个时候的最好、最坏和平均复杂度非常接近
		第二种情况，我用 a<b 来表示，表示从 a 点出发，每个点的直接连接数量远远小于从 b 点出发的那些
		第三种情况和第二种类似，我用 a>b 表示，表示从 b 点出发，每个点的直接连接数量远远小于从 a 点出发的那
		对于第二和第三种情况，双向搜索的最坏、最好和平均的复杂度是多少？还会是双向的方法更优吗？
			参见第 14 讲的思考题
案例分析二：全文搜索
	搜索引擎最基本的也最重要的功能，就是根据你输入的关键词，查找指定的数据对象。要查找某个关键词是不是出现在一篇文章里，最基本的处理方式有两种
	第一，把全文作为一个很长的字符串，把用户输入的关键词作为一个子串，那这个搜索问题就变成了子串匹配的问题
		假设字符串平均长度为 n 个字符，关键词平均长度为 m 个字符，使用最简单的暴力法，就是把代表全文的字符串的每个字符，和关键词字符串的每个字符两两相比，那么时间复杂度就是 O(n*m)
	第二，对全文进行分词，把全文切分成一个个有意义的词，那么这个搜索问题就变成了把输入关键词和这些切分后的词进行匹配的问题
		拉丁文分词比较简单，基本上就是根据各种分隔符来切分。而中文分词涉及很多算法，不过这不是我们讨论的重点，我们假设无论何种语言、何种分词方法，时间复杂度都是 O(n)，其中 n 为文章的长度
		而在词的集合中查找输入的关键词，时间复杂度是 O(m)，m 为词集合中元素的数量
			我们也可以先对词的集合排序，时间复杂度是 O(m*logm)，然后使用二分查找，时间复杂度都只有 O(logm)
			如果文章很少改变，那么全文的分词和词的排序，基本上都属于一次性的开销，对于关键词查询来说，每次的时间复杂度都只有 O(logm)
		假设文章数量是 k，那么时间复杂度就变为 O(k*n)，或者 O(k*logm)，数量级一下子就增加了
			为了降低搜索引擎在查询时候的时间复杂度，我们要引入倒排索引（或逆向索引），这就是典型的牺牲空间来换取时间
			假设有 n 个不同的单词，而每个单词所对应的文章平均数为 m 的话，那么这种索引的空间复杂度就是 O(n*m)。好在 n 和 m 通常不会太大，对内存和磁盘的消耗都是可以接受的

思考
	在你日常的工作中，有没有经历过性能分析相关的项目？如果有，你都使用了哪些方法来分析问题的症结？
*/
